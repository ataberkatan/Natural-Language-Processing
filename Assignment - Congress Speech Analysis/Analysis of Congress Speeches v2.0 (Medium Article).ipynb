{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Analysis of Congress Speeches\n",
    "### By calculating the Cosine Similarities and Manhattan Distances between the TF-IDF (term frequency-inverse document frequency) and Count Vectors of texts with n-grams\n",
    "Using *N* speeches of my choosing,<br />\n",
    "preparing them for analysis (removing punctuation, stop-words),<br />\n",
    "using Bag of Words and n-grams in addition to tf-idf to find the cosine similarity between them.<br />\n",
    "Discussing my findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "%pip install -U scikit-learn\n",
    "%pip install nltk \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text1_url = \"https://raw.githubusercontent.com/ariedamuco/ML-for-NLP/main/Inputs/105-extracted-date/105-moseleybraun-il.txt\"\n",
    "text2_url = \"https://raw.githubusercontent.com/ariedamuco/ML-for-NLP/main/Inputs/105-extracted-date/105-reid-nv.txt\"\n",
    "\n",
    "text1_get, text2_get = requests.get(text1_url), requests.get(text2_url)\n",
    "text1, text2 = text1_get.text, text2_get.text\n",
    "\n",
    "print(\"text1 head:\\n\",text1[0:200],\"\\n\\ntext2 head:\\n\",text2[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Loading the chosen speech texts:\n",
    "text1 = open(r\"Congress Speeches\\105-moseleybraun-il.txt\").read()\n",
    "text2 = open(r\"Congress Speeches\\105-reid-nv.txt\").read()\n",
    "\n",
    "# Printing the first 200 characters:\n",
    "print(\"text1 head:\\n\",text1[0:200],\"\\n\\ntext2 head:\\n\",text2[0:200])\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing punctuation and stop-words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor(text):\n",
    "    # Deleting non-word characters by replacing them with blank (' '):\n",
    "    text= re.sub(r'\\W',' ', text)\n",
    "    # Tokenizing the string text into word substrings, writing them to a list (.lower() makes all characters lower case):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Removing English stopwords from the list:\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # Keeping words with at least 3 characters in the list:\n",
    "    tokens = [word for word in tokens if len(word)>=3]\n",
    "    # Joining the tokens -substrings- in the list back together with blank (' ') between them:\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the pre-processing function with the first 1000 characters of the first text:\n",
    "text1_head_tokenized = text_preprocessor(text1[:1000])\n",
    "text1_head_tokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming the words in the tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    # Creating a stemmer instance which uses Porter Stemming Algorithm:\n",
    "    stemmer = PorterStemmer()\n",
    "    # Tokenizing the text into words, stemming them:\n",
    "    stemmed_words = [stemmer.stem(word) for word in word_tokenize(text)]\n",
    "    # Joining the word stems back and returning:\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Some alternatives to Porter in NLTK are Snowball (in English) and Lancaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the stemmer function:\n",
    "text1_stemmed = stem_words(text1_head_tokenized)\n",
    "text1_stemmed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatizing the words in the tokenized and stemmed text\n",
    "[Lemmatisation](https://en.wikipedia.org/wiki/Lemmatisation) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    # Creating a lemmatizer instance:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Applying the lemmatizer word by word:\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "    # Joining the words back and returning:\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the lemmatizer function:\n",
    "text1_lemmatized = lemmatize_words(text1_stemmed)\n",
    "text1_lemmatized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "Now that all the pre-processing functions are tested and working, we can apply the functions to full bodies of both texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(text):\n",
    "    step1 = text_preprocessor(text)\n",
    "    step2 = stem_words(step1)\n",
    "    step3 = lemmatize_words(step2)\n",
    "    output = step3\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_processed, text2_processed = text_processor(text1), text_processor(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_processed[:500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We represent the processed bodies of text as vectors to analyze them. We use both TF-IDF and Bag-of-Words (Count) approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Calling an instance of TF-IDF Vectorizer with default arguments:\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Calling an instance of Count Vectorizer with default arguments:\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the bodies of texts and putting them together in a matrix:\n",
    "corpus_tfidf = tfidf_vectorizer.fit_transform([text1_processed, text2_processed])\n",
    "corpus_count = count_vectorizer.fit_transform([text1_processed, text2_processed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Transforming the corpus matrix to a dataframe with feature names (words) as index:\n",
    "corpus_tfidf_matrix = pd.DataFrame(corpus_tfidf.toarray().transpose(), \n",
    "                             index=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "corpus_count_matrix = pd.DataFrame(corpus_count.toarray().transpose(), \n",
    "                             index=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Renaming the columns with the names of the senators who gave the speeches:\n",
    "corpus_tfidf_matrix = corpus_tfidf_matrix.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)\n",
    "\n",
    "corpus_count_matrix = corpus_count_matrix.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculating the cosine similarity between to the vectorized texts:\n",
    "tfidf_result = cosine_similarity(corpus_tfidf_matrix[corpus_tfidf_matrix.columns[0]].values.reshape(1, -1), \n",
    "                  corpus_tfidf_matrix[corpus_tfidf_matrix.columns[1]].values.reshape(1, -1))\n",
    "\n",
    "bow_result = cosine_similarity(corpus_count_matrix[corpus_count_matrix.columns[0]].values.reshape(1, -1), \n",
    "                  corpus_count_matrix[corpus_count_matrix.columns[1]].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Similarity rate with TF-IDF:\", tfidf_result, \n",
    "      \"\\nSimilarity rate with Bag-of-Words:\", bow_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let us see how the results change if we look at 2-grams and 3-grams cumulatively in addition to single words.\n",
    "\n",
    "We need to modify the vectorizers in order to achieve this. Previously, we used the vectorizers with default parameters. This means that they only looked at single words instead of groups of two or three consecutive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling an instance of TF-IDF Vectorizer with 1 to 2 grams:\n",
    "tfidf_vectorizer_12 = TfidfVectorizer(ngram_range = (1,2))\n",
    "\n",
    "# Calling an instance of Count Vectorizer with 1 to 2 grams:\n",
    "count_vectorizer_12 = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "# I name the vectorizers with the \"_12\" suffix, indicating the ngram_range parameter values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we call the vectorizers to look at 1 and 2-grams together. We could also look at 2-grams only instead by setting the ngram_range parameter to (2,2) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the bodies of texts and putting them together in a matrix:\n",
    "corpus_tfidf_12 = tfidf_vectorizer_12.fit_transform([text1_processed, text2_processed])\n",
    "corpus_count_12 = count_vectorizer_12.fit_transform([text1_processed, text2_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the corpus matrix to a dataframe with feature names (words) as index:\n",
    "corpus_tfidf_matrix_12 = pd.DataFrame(corpus_tfidf_12.toarray().transpose(), \n",
    "                             index=tfidf_vectorizer_12.get_feature_names_out())\n",
    "\n",
    "corpus_count_matrix_12 = pd.DataFrame(corpus_count_12.toarray().transpose(), \n",
    "                             index=count_vectorizer_12.get_feature_names_out())\n",
    "\n",
    "# Renaming the columns with the names of the senators who gave the speeches:\n",
    "corpus_tfidf_matrix_12 = corpus_tfidf_matrix_12.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)\n",
    "\n",
    "corpus_count_matrix_12 = corpus_count_matrix_12.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_count_matrix_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_matrix_12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define functions for similarity measures to make life easier in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_result(matrix):\n",
    "    result = cosine_similarity(matrix[matrix.columns[0]].values.reshape(1, -1), \n",
    "                               matrix[matrix.columns[1]].values.reshape(1, -1))\n",
    "    return result\n",
    "\n",
    "tfidf_result_12 = cosine_result(corpus_tfidf_matrix_12)\n",
    "bow_result_12 = cosine_result(corpus_count_matrix_12)\n",
    "\n",
    "print(\"Similarity rate with TF-IDF:\", tfidf_result,\n",
    "      \"\\nSimilarity rate with Bag-of-Words:\", bow_result, \n",
    "      \"\\nSimilarity rate with TF-IDF, 1 to 2-grams:\", tfidf_result_12, \n",
    "      \"\\nSimilarity rate with Bag-of-Words, 1 to 2-grams:\", bow_result_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "def manhattan_result(matrix):\n",
    "    result = manhattan_distances(matrix[matrix.columns[0]].values.reshape(1, -1), \n",
    "                               matrix[matrix.columns[1]].values.reshape(1, -1))\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define another function which takes two processed texts, ngram_range parameters and vectorizer as input and returns cosine similarity between the two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_pipeline(vectorizer, txt1, txt2, ngram_range = (1,1), similarity = \"Cosine\"):\n",
    "    \n",
    "    # Allowing the option to use Tfidf and Count vectorizers:\n",
    "    if vectorizer == \"Count\":\n",
    "        \n",
    "        # Calling the vectorizer with desired ngram_range values, (1,1) applies if not specified:\n",
    "        count_vectorizer = CountVectorizer(ngram_range = ngram_range)\n",
    "        \n",
    "        corpus_count = count_vectorizer.fit_transform([txt1, txt2])\n",
    "\n",
    "        # Loading vectorized texts into a matrix:\n",
    "        corpus_count_matrix = pd.DataFrame(corpus_count.toarray().transpose(), \n",
    "                             index=count_vectorizer.get_feature_names_out())\n",
    "        \n",
    "        # Renaming the columns:\n",
    "        corpus_count_matrix = corpus_count_matrix.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)\n",
    "        \n",
    "        # Defining the output:\n",
    "        if similarity == \"Cosine\":\n",
    "            output = cosine_result(corpus_count_matrix)\n",
    "\n",
    "        elif similarity == \"Manhattan\":\n",
    "            output = manhattan_result(corpus_count_matrix)\n",
    "\n",
    "        else:\n",
    "            print(\"Please choose a valid parameter for similarity.\",\n",
    "                  \"\\nValid similarity measures are 'Cosine' and 'Manhattan'.\")\n",
    "    \n",
    "    elif vectorizer == \"Tfidf\":\n",
    "        # Calling the vectorizer with desired ngram_range values, (1,1) applies if not specified:\n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range = ngram_range)\n",
    "        \n",
    "        corpus_tfidf = tfidf_vectorizer.fit_transform([txt1, txt2])\n",
    "\n",
    "        # Loading vectorized texts into a matrix:\n",
    "        corpus_tfidf_matrix = pd.DataFrame(corpus_tfidf.toarray().transpose(), \n",
    "                             index=tfidf_vectorizer.get_feature_names_out())\n",
    "        \n",
    "        # Renaming the columns:\n",
    "        corpus_tfidf_matrix = corpus_tfidf_matrix.set_axis([\"Moseley-Braun\",\"Reid\"], \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)\n",
    "        \n",
    "        # Defining the output:\n",
    "        if similarity == \"Cosine\":\n",
    "            output = cosine_result(corpus_tfidf_matrix)\n",
    "\n",
    "        elif similarity == \"Manhattan\":\n",
    "            output = manhattan_result(corpus_tfidf_matrix)\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Please choose valid parameters for vectorizer and similarity measure.\",\n",
    "              \"\\nValid vectorizers are 'Count' and 'Tfidf'.\",\n",
    "              \"\\nValid similarity measures are 'Cosine' and 'Manhattan'.\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function:\n",
    "similarity_pipeline(\"Tfidf\", text1_processed, text2_processed, ngram_range = (2,2), similarity= \"Manhattan\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check results comparatively, produced from different vectorizers and specifications of n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_ranges = [(1,1), (1,2), (1,3), (1,4), (2,2), (3,3), (4,4)]\n",
    "vectorizers = [\"Tfidf\", \"Count\"]\n",
    "similarity_measures = [\"Cosine\", \"Manhattan\"]\n",
    "results = []\n",
    "for vec in vectorizers:\n",
    "    for ngram_range in ngram_ranges:\n",
    "        for similarity_measure in similarity_measures:\n",
    "            if vec == \"Tfidf\":\n",
    "                if similarity_measure == \"Cosine\":\n",
    "                    score = similarity_pipeline(vec, text1_processed, text2_processed, ngram_range=ngram_range, similarity=\"Cosine\")\n",
    "                    results.append({\"Vectorizer\": vec, \"Similarity Measure\": similarity_measure, \"Ngram Range\": ngram_range, \"Similarity Score\": score[0][0]})\n",
    "                else:\n",
    "                    score = similarity_pipeline(vec, text1_processed, text2_processed, ngram_range=ngram_range, similarity=\"Manhattan\")\n",
    "                    results.append({\"Vectorizer\": vec, \"Similarity Measure\": \"Manhattan\", \"Ngram Range\": ngram_range, \"Similarity Score\": score[0][0]})\n",
    "            else:\n",
    "                if similarity_measure == \"Cosine\":\n",
    "                    score = similarity_pipeline(vec, text1_processed, text2_processed, ngram_range=ngram_range, similarity=\"Cosine\")\n",
    "                    results.append({\"Vectorizer\": \"Bag-of-Words\", \"Similarity Measure\": similarity_measure, \"Ngram Range\": ngram_range, \"Similarity Score\": score[0][0]})\n",
    "                else:\n",
    "                    score = similarity_pipeline(vec, text1_processed, text2_processed, ngram_range=ngram_range, similarity=\"Manhattan\")\n",
    "                    results.append({\"Vectorizer\": \"Bag-of-Words\", \"Similarity Measure\": \"Manhattan\", \"Ngram Range\": ngram_range, \"Similarity Score\": score[0][0]})\n",
    " \n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "To qualitatively discuss the similarity between the two senators' speeches some background on who they are is needed.\n",
    "\n",
    "[**Moseley-Braun**](https://en.wikipedia.org/wiki/Carol_Moseley_Braun) was *the first African-American woman* elected to the U.S. Senate, the first African-American U.S. Senator from the **Democratic Party**, *the first woman to defeat an incumbent U.S. Senator in an election*, and the first female U.S. Senator from Illinois.\n",
    "\n",
    "[**Harry Mason Reid Jr.**](https://en.wikipedia.org/wiki/Harry_Reid) was an American lawyer and politician who served as a United States senator from Nevada from 1987 to 2017. He *led the Senate **Democratic** Caucus from 2005 to 2017* and was *the Senate Majority Leader from 2007 to 2015*.\n",
    "\n",
    "Although both senators were from the same party, the dissimilarity between them should most likely to be rooted in their backgrounds and identities they stand for.\n",
    "\n",
    "Moseley-Braun had been the first to set many milestones while Reid's election and re-ellection has arguably been in smoother conditions. Moseley-Braun is an African-American woman to be the first female U.S. Senator in her state while Reid is from an already well represented identity group - white and male.\n",
    "\n",
    "The similarity being above 50% might be due to the fact that they are from the same party but the present difference is, at least superficially, because they are vastly different character and from very different states.\n",
    "\n",
    "For a better grounded analysis, we can look at the similarity measures of multiple pairs of senator speeches from the same and different parties and employ a comparative perspective. This approach can reveal patterns more clearly as to what makes two speeches similar and what having similar speeches tells us about the characteristics of the senators in comparison. Furthermore, different methods of vectorizing speeches and different measures of similarity might give qualitatively different results.\n",
    "\n",
    "For instance, we found here a similarity of 65%. A good reference point would be the average level of similarity between senators of the two different parties.\n",
    "\n",
    "##### What about when we use a different vectorizer and look at different n-gram ranges?\n",
    "\n",
    "- **Observation 1**: We see that for every n-gram range, Bag-of-Words gives a higher cosine similarity. This is because TF-IDF is more restrictive. While Bag-of-Words simply records how many times each word is used in both texts, TF-IDF (Term Frequency-Inverse Document Frequency) gives a measure of how often word i (or n-gram i) appeared in text j, penalized by the number of texts also containing word i. In other words, the weight of a word is proportional to its frequency in the document (term frequency) and inversely proportional to its frequency across the corpus (inverse document frequency). Words that are common across the corpus (i.e., appear in many documents) receive a lower weight, while words that are rare in the corpus receive a higher weight.\n",
    "\n",
    "- **Observation 2**: We look n-grams alone and cumulatively i.e., 1, 2 and 3-grams together for (1,3) n-gram range. If we take the first case, looking at 2-grams or 3-grams alone, we see for both vectorizers the cosine similarities strictly decrease as we look at larger grams. In the cumulative case, we see again cosine similarities decreasing. However, the decrease in this case is slower because it is easier to get a high measure of cosine similarity when looking at 1-grams than 2-grams and easier when looking at 2-grams than 3-grams. Looking at a range of 1 to 3 grams rather than just 3 grams results in higher cosine similarity due to the above logic.\n",
    "\n",
    "##### What about a different similarity measure?\n",
    "We also look at *Manhattan Distance* measures between text vectors. Manhattan Distance is the distance between two vectors as the sum of the absolute differences between the elements of the two vectors. It is also known as L1 distance. A lower value indicates greater similarity. See [Taxicab Geometry](https://en.wikipedia.org/wiki/Taxicab_geometry).\n",
    "\n",
    "Since it is a distance measure, the lower the value, the more similar the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Similarity Measure\"] == \"Manhattan\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with Manhattan Distance as the similarity measure mirrors the results when we used cosine similarity in terms of comparing within the same vectorizer i.e., with a given vectorizer, the observation about using different n-gram ranges hold here.\n",
    "\n",
    "But since the [*Manhattan Distance*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.manhattan_distances.html#sklearn.metrics.pairwise.manhattan_distances) measure in **sci-kit learn** library is not a standardized measure like *Cosine Similarity*, we cannot compare along the results from different vectorizers with the same n-gram range.\n",
    "\n",
    "For instance, if we look at the the Manhattan Score using Bag-of-Words with 1-grams and the corresponding score using TF-IDF, we cannot infer that there is a dissimilarity of the order of thousands between the two scores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What else can be done in future projects?\n",
    "\n",
    "- Corpus specific useless words can be eliminated during the text processing stage.\n",
    "- More steps can be written as functions to avoid unnecessary code repetition.\n",
    "- A pipeline can be constructed in order to check among N texts, which one is the most similar to a given text. For example, among all the senator speeches we have, which one is the most similar to a given senator's e.g., Senator Biden's."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us now look at among the speech texts we have which one is the most similar to Senator Biden's.\n",
    "We use;\n",
    "- TF-IDF to vectorize,\n",
    "- Cosine similarity to compare similarities, and,\n",
    "- Cumulative 2-grams i.e., 1-grams and 2-grams together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the URLs that contain the text files:\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "html = requests.get('https://github.com/ariedamuco/ML-for-NLP/tree/main/Inputs/105-extracted-date')\n",
    "\n",
    "text_links = []\n",
    "\n",
    "for link in BeautifulSoup(html.text, parse_only=SoupStrainer('a')):\n",
    "    if hasattr(link, 'href') and link['href'].endswith('.txt'):\n",
    "        url = \"https://raw.githubusercontent.com\" + link['href'].replace('/blob/', '/')\n",
    "        text_links.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all the texts into a dictionary:\n",
    "\n",
    "text_dict = {}\n",
    "\n",
    "for i, text_url in enumerate(text_links):\n",
    "    text_get = requests.get(text_url)\n",
    "    text = text_get.text\n",
    "    \n",
    "    key = 'text{}'.format(i+1)\n",
    "    text_dict[key] = text\n",
    "\n",
    "# The key for Senator Biden is 'text7'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "text7 = text_dict.pop('text7')\n",
    "\n",
    "keys = list(text_dict.keys())\n",
    "\n",
    "random_keys = random.sample(keys, 10)\n",
    "\n",
    "#random_keys.append('text7')\n",
    "\n",
    "random_text_dict = {key: text_dict[key] for key in random_keys}\n",
    "\n",
    "random_text_dict['text7'] = text7\n",
    "\n",
    "random_text_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text_dict = {}\n",
    "\n",
    "for key, text in random_text_dict.items():\n",
    "    processed_text = text_processor(text)\n",
    "    \n",
    "    processed_text_dict[key] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(processed_text_dict.keys())\n",
    "processed_text_dict['text7'][:10000000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "corpus = tfidf_vectorizer_12.fit_transform([text1_processed, text2_processed])\n",
    "\"\"\"\n",
    "corpus = tfidf_vectorizer_12.fit_transform(processed_text_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_matrix = pd.DataFrame(corpus.toarray().transpose(), \n",
    "                             index=tfidf_vectorizer_12.get_feature_names_out())\n",
    "\n",
    "# Renaming the columns with the names of the senators who gave the speeches:\n",
    "corpus_matrix = corpus_matrix.set_axis(list(processed_text_dict.keys()), \n",
    "                                       axis = \"columns\", \n",
    "                                       copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text65</th>\n",
       "      <th>text71</th>\n",
       "      <th>text24</th>\n",
       "      <th>text64</th>\n",
       "      <th>text98</th>\n",
       "      <th>text75</th>\n",
       "      <th>text3</th>\n",
       "      <th>text33</th>\n",
       "      <th>text22</th>\n",
       "      <th>text89</th>\n",
       "      <th>text7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "      <td>594771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.294466</td>\n",
       "      <td>0.334740</td>\n",
       "      <td>0.367506</td>\n",
       "      <td>0.327415</td>\n",
       "      <td>0.390923</td>\n",
       "      <td>0.315102</td>\n",
       "      <td>0.361866</td>\n",
       "      <td>0.283449</td>\n",
       "      <td>0.299334</td>\n",
       "      <td>0.280597</td>\n",
       "      <td>0.298016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text65         text71         text24         text64  \\\n",
       "count  594771.000000  594771.000000  594771.000000  594771.000000   \n",
       "mean        0.000114       0.000090       0.000066       0.000091   \n",
       "std         0.001292       0.001294       0.001295       0.001293   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         0.294466       0.334740       0.367506       0.327415   \n",
       "\n",
       "              text98         text75          text3         text33  \\\n",
       "count  594771.000000  594771.000000  594771.000000  594771.000000   \n",
       "mean        0.000056       0.000113       0.000089       0.000100   \n",
       "std         0.001295       0.001292       0.001294       0.001293   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         0.390923       0.315102       0.361866       0.283449   \n",
       "\n",
       "              text22         text89          text7  \n",
       "count  594771.000000  594771.000000  594771.000000  \n",
       "mean        0.000092       0.000101       0.000110  \n",
       "std         0.001293       0.001293       0.001292  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         0.299334       0.280597       0.298016  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_matrix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col_name in enumerate(list(corpus_matrix.columns)):\n",
    "    globals()[\"TFIDF_\" + str(col_name)] =corpus_matrix[corpus_matrix.columns[i]].values.reshape(1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities_dict = {'Cosine Similarity': 'NaN', 'Text': (list(corpus_matrix.columns))}\n",
    "cosine_similarities = pd.DataFrame(data=cosine_similarities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity    Text\n",
       "0                NaN  text65\n",
       "1                NaN  text71\n",
       "2                NaN  text24\n",
       "3                NaN  text64\n",
       "4                NaN  text98\n",
       "5                NaN  text75\n",
       "6                NaN   text3\n",
       "7                NaN  text33\n",
       "8                NaN  text22\n",
       "9                NaN  text89\n",
       "10               NaN   text7"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col_name in enumerate(list(corpus_matrix.columns)):\n",
    "    cosine_similarities['Cosine Similarity'][i] = cosine_similarity(TFIDF_text7, globals()[\"TFIDF_\" + str(col_name)])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarities.drop(index=cosine_similarities[cosine_similarities['Text'] == 'text7'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities['Cosine Similarity'] = cosine_similarities['Cosine Similarity'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cosine Similarity    0.646906\n",
       "Text                   text65\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = cosine_similarities['Cosine Similarity'].idxmax()\n",
    "\n",
    "cosine_similarities.loc[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc docno 105 leahi 19981021 docno text leahi presid american peopl grow concern encroach person privaci seem everywher turn new technolog new commun medium new busi servic creat best intent highest expect also pose threat abil keep live live work think without giant corpor govern look shoulder peek keyhol current nation medium ob monica lewinski scandal focus attent abus power independ counsel kenneth starr prosecutor intim familiar enorm power prosecutor wield power gener circumscrib sen honor profession enough bar canon ethic disciplinari rule feder prosecutor rule regul depart justic starr differ view oblig privaci first casualti began investig presid person life use result illeg wiretap state maryland protect resid privat convers tape record without knowledg consent starr condon deliber flout law grant perpetr immun use illicit record persuad attorney gener expand jurisdict begin februari prosecutor starr forc mother travel countri capit sit feder grand juri right counsel present '"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text_dict['text65'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/ariedamuco/ML-for-NLP/main/Inputs/105-extracted-date/105-leahy-vt.txt'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_links[65-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Patrick_Leahy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dd99e0ac365466ae650ff45d8775d59e259e5553338a3c6426640fcc04918b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
